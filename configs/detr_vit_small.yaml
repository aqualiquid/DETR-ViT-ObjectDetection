# DETR-ViT Small Configuration
model:
  name: "detr_vit_small"
  backbone: "vit_small_patch16"
  num_classes: 91
  num_queries: 100
  hidden_dim: 256
  nheads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  dropout: 0.1

training:
  batch_size: 16
  learning_rate: 1e-4
  weight_decay: 1e-4
  epochs: 100
  warmup_epochs: 10
  clip_max_norm: 0.1

data:
  dataset: "coco"
  data_path: "data/raw/coco"
  num_workers: 4
  pin_memory: true
  
  transforms:
    resize: [512, 864]
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

optimizer:
  name: "adamw"
  lr_scheduler: "step"
  lr_drop: 40

logging:
  log_dir: "results/logs"
  save_checkpoint_every: 10
  eval_every: 5

device: "auto"
